{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP4FY7tbqcDireVL9zysXIn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyans-sureja/llm-101/blob/main/23_e2e_revision_note.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-Cow8ZF2oBn",
        "outputId": "4d7014a5-f053-463d-930a-16b9e74d2de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/shreyans-sureja/llm-101/main/data/the-verdict.txt\"\n",
        "response = requests.get(url)\n",
        "text_data = response.text\n",
        "\n",
        "print(\"Total number of characters:\", len(text_data))\n",
        "print(text_data[:99])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (original: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n"
      ],
      "metadata": {
        "id": "Q5Ffvxm125xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlOey4Wm27un",
        "outputId": "fdef5c38-0814-4334-edd5-5f706f7c89b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Validation ratio\n",
        "train_ratio = 0.9\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]"
      ],
      "metadata": {
        "id": "4hWeqVrv4Dpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # tokenize\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # slinging window to chunk the book into max_length sequence\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i+max_length]\n",
        "            target_chunk = token_ids[i+1: i+max_length+1]\n",
        "\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    # tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # create dataloader\n",
        "    dataloader = DataLoader(dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=shuffle,\n",
        "                            drop_last=drop_last,\n",
        "                            num_workers=num_workers\n",
        "                            )\n",
        "\n",
        "    return dataloader\n"
      ],
      "metadata": {
        "id": "AhbkuGCB4GKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed_all(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "Cgx9ULLt4YTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check\n",
        "# token should not less than context length\n",
        "\n",
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the training loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"increase the `training_ratio`\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the validation loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"decrease the `training_ratio`\")"
      ],
      "metadata": {
        "id": "HBOh39544fFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verifying data is loaded correctly\n",
        "\n",
        "train_tokens = 0\n",
        "for input_batch, target_batch in train_loader:\n",
        "    train_tokens += input_batch.numel()\n",
        "\n",
        "val_tokens = 0\n",
        "for input_batch, target_batch in val_loader:\n",
        "    val_tokens += input_batch.numel()\n",
        "\n",
        "print(\"Training tokens:\", train_tokens)\n",
        "print(\"Validation tokens:\", val_tokens)\n",
        "print(\"All tokens:\", train_tokens + val_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibbM2xT64iEW",
        "outputId": "8a94c415-cdeb-4ca7-d4b7-87d3ace0ed50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tokens: 4608\n",
            "Validation tokens: 512\n",
            "All tokens: 5120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # approx GeLu function\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "        (x + 0.044715 * torch.pow(x, 3))\n",
        "    ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "6aveUmov4ntE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # Use a placeholder for TransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        # Use a placeholder for LayerNorm\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "\n",
        "        # dropout helps in generalization and avoid overfitting\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "T-tPVpLS5E3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device.\")\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2MCQUA1D-zk7",
        "outputId": "99e6c716-a8dc-49d4-af22-a62e622a26e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "         # Reduce the number of batches to match the total number of batches in the data loader\n",
        "         # if num_batches exceeds the number of batches in the data loader\n",
        "         num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n"
      ],
      "metadata": {
        "id": "YBJ4-ZZi_WR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "torch.cuda.manual_seed_all(123)\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmv1vwGH_E9I",
        "outputId": "30313118-0102-4940-903c-5e9b20286c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 11.000460306803385\n",
            "Validation loss: 11.03061294555664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    # Set model to evaluation mode (disables dropout, uses running stats for batchnorm)\n",
        "    model.eval()\n",
        "    with torch.no_grad():  # Disable gradient computation to save memory and speed up\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    # Switch back to training mode so subsequent training steps behave correctly\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ],
      "metadata": {
        "id": "F822nRdw_a2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ],
      "metadata": {
        "id": "S_itGR3D_7hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "froBaz33AEAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate(\n",
        "          model=model,\n",
        "          idx=encoded,\n",
        "          max_new_tokens=50,\n",
        "          context_size=context_size,\n",
        "          top_k=25,\n",
        "          temperature=1.4\n",
        "        )\n",
        "\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "lmd1zSz4AA43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "\n",
        "            # calculate the gradient of loss with all of the parameters of the 160M\n",
        "            loss.backward() # Calculate loss gradients\n",
        "\n",
        "            # new_weight = old_weigth - alpha * gradient (similar to this)\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "tBH5mwGWAGPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed_all(123)\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGTblmbiANEj",
        "outputId": "17909772-e3d2-48d8-c447-e38593a9fa57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.818, Val loss 9.930\n",
            "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.336\n",
            "Every effort moves you the had the, the to.'t it of, that me of, the. his.   a        that it on the with my--.    \", he in I- he.,\n",
            "Ep 2 (Step 000010): Train loss 6.623, Val loss 7.053\n",
            "Ep 2 (Step 000015): Train loss 6.046, Val loss 6.604\n",
            "Every effort moves you the my\" to he was he, it. his itI-- he to the his had, a. to him have with was't.-- my, it was to have the his had with to-- of the I my had of a his\n",
            "Ep 3 (Step 000020): Train loss 5.527, Val loss 6.511\n",
            "Ep 3 (Step 000025): Train loss 5.382, Val loss 6.375\n",
            "Every effort moves you.\" \" his--I!--Oh, the't, with and and in in the of his St that my't it had to didn, a was his of ais of I was his! I felt- it, as of her, he\n",
            "Ep 4 (Step 000030): Train loss 4.829, Val loss 6.249\n",
            "Ep 4 (Step 000035): Train loss 4.670, Val loss 6.318\n",
            "Every effort moves you the hisI and my own picture to \"Yes Mrs. But  And I had Jack \"'t-- her.  \"-- him. Gisburn said\" I said it. The to   II was he was me\n",
            "Ep 5 (Step 000040): Train loss 3.920, Val loss 6.127\n",
            "Every effort moves you one with they the donkey--that of his eyes the Rivas such I couldn and, he knew.\"  He he had been_ to me the house his pictures placed I could a smile.  I I felt--oh,, my of\n",
            "Ep 6 (Step 000045): Train loss 3.570, Val loss 6.175\n",
            "Ep 6 (Step 000050): Train loss 3.013, Val loss 6.119\n",
            "Every effort moves you'd terrace. Stroud laid. Gisburn--all that when I had been the his was with the light in his that the fact it happened the his glory of his painting because his pictures that.\"   I had been I had\n",
            "Ep 7 (Step 000055): Train loss 2.885, Val loss 6.145\n",
            "Ep 7 (Step 000060): Train loss 2.159, Val loss 6.131\n",
            "Every effort moves you know you in him down that tried the picture--it of one in to on one like an--for--\"ieraed to her husband a note. back a later-t--only--\"I didn't bear Jack's the hour by him\n",
            "Ep 8 (Step 000065): Train loss 1.723, Val loss 6.169\n",
            "Ep 8 (Step 000070): Train loss 1.421, Val loss 6.237\n",
            "Every effort moves you get his eyes on-rooms, so after_ Mrs. \"Oh, it to say an exquisburn's of resolve had to the picture was said out Jack himself at my elbow and get aside a good; and \"strong up as his\n",
            "Ep 9 (Step 000075): Train loss 1.083, Val loss 6.255\n",
            "Ep 9 (Step 000080): Train loss 0.823, Val loss 6.290\n",
            "Every effort moves you?\" \"  A felt him insignificant--I--quite forward him--I didn't _ they--and here reass constraint crossed Mrs. And behind his close that to look it. She couldn't you know, and were amusing himself by now\n",
            "Ep 10 (Step 000085): Train loss 0.594, Val loss 6.384\n",
            "Every effort moves you was what through my surprise, one of the picture--so handsome sun in the so when she began to stammer something about her sp of the height of his glory quality_ interesting--if I saw that, married the honour--the. And\n",
            "Training completed in 0.54 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    # plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "fBdSpp2LAN-X",
        "outputId": "2dabb315-5eb6-433b-a0ef-96b37cf5efd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}