{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPe4AOb4M2okpQEUbLPiLhV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyans-sureja/llm-101/blob/main/part4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Token Embeddings"
      ],
      "metadata": {
        "id": "NRAvp2RAyYqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Input text broke into tokens\n",
        "- Tokens converted into token Ids\n",
        "- TokenIds converted into token embeddings\n",
        "- Embeddings serves as input in LLM."
      ],
      "metadata": {
        "id": "X1oZ18_PyfNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are token embeddings and why they are needed?\n",
        "\n",
        "- how can we represent words in numbers as computer does not understand words?\n",
        "- that's why we created vocab\n",
        "\n",
        "\n",
        "Why can't we use this token ids and need token embeddings?\n",
        "- cat and kitten are semantically related but associated token ids can't capture that.\n",
        "\n",
        "\n",
        "What about one-hot encoding?\n",
        "- still fails to capture semantic relationship\n",
        "\n",
        "How to encode semantic meaning?\n",
        "- semantically similar words should have similar vectors\n",
        "- create feature vector representation and values associated to similar feature will have close values and hence get close vector representation than other items.\n",
        "- we can train a neural network to create vector embedding."
      ],
      "metadata": {
        "id": "Lm7Dfh65zKSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many companies have pre-trained token embedding\n",
        "- example: Google news https://huggingface.co/fse/word2vec-google-news-300\n",
        "- this model contains 300 dimensional vectors for 3 million words and phrases.\n"
      ],
      "metadata": {
        "id": "a9bqcaa03oDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U gensim"
      ],
      "metadata": {
        "id": "DAl-w3N-y9An",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d09de2-7450-43f8-b0e3-2eb19b37c53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "d10YfGfy9XcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUxlDIsU9sjr",
        "outputId": "859302cb-8570-4ebc-b70f-34b1475dd25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = model"
      ],
      "metadata": {
        "id": "ER3qmAb393Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(word_vectors))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTVxtkQm_zrh",
        "outputId": "49419c87-adcc-4973-c995-f172eb9fc748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'gensim.models.keyedvectors.KeyedVectors'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors['india'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auZ7kqnX_4EH",
        "outputId": "fa691295-ee91-41a7-f6ae-15cb9ae3df32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.34375000e-01 -7.17773438e-02  1.05590820e-02  3.26171875e-01\n",
            " -6.29882812e-02 -1.78710938e-01  3.17382812e-02 -3.96484375e-01\n",
            " -1.69921875e-01 -3.54003906e-02 -1.81640625e-01 -3.28125000e-01\n",
            "  6.59179688e-02 -2.07031250e-01  1.19140625e-01  1.74804688e-01\n",
            " -1.10839844e-01  3.30078125e-01  5.20019531e-02 -2.47802734e-02\n",
            "  1.48773193e-03 -1.60156250e-01  2.70996094e-02 -1.80664062e-01\n",
            " -4.14062500e-01  1.95312500e-01 -3.49609375e-01  1.03515625e-01\n",
            " -8.54492188e-02 -1.48437500e-01 -8.25195312e-02 -2.90527344e-02\n",
            " -3.02734375e-01  1.98974609e-02 -3.26171875e-01  1.70898438e-01\n",
            " -4.55078125e-01 -4.39453125e-03  4.27734375e-01 -2.13867188e-01\n",
            " -6.86645508e-03  1.23535156e-01  4.96093750e-01  3.41796875e-01\n",
            "  1.70898438e-01 -1.56250000e-01 -9.42382812e-02 -5.73730469e-02\n",
            " -1.95312500e-01  6.44531250e-02 -1.49414062e-01  1.58203125e-01\n",
            "  2.53906250e-01  2.13867188e-01 -2.85156250e-01 -2.77343750e-01\n",
            " -2.24609375e-01 -2.96875000e-01 -7.17163086e-03 -3.47656250e-01\n",
            " -6.89697266e-03  8.39843750e-02 -6.34765625e-02 -1.89453125e-01\n",
            " -1.02539062e-01 -1.64062500e-01  4.06265259e-04 -3.34472656e-02\n",
            " -2.51953125e-01  8.69140625e-02 -2.41210938e-01  2.63671875e-01\n",
            " -1.25000000e-01  4.51660156e-02 -3.47656250e-01 -1.84570312e-01\n",
            "  1.46484375e-03  1.77734375e-01 -2.85156250e-01  2.44140625e-02\n",
            " -2.53906250e-01  2.15820312e-01 -1.83593750e-01 -2.33398438e-01\n",
            " -1.79290771e-03  1.26953125e-01 -1.38671875e-01 -1.29882812e-01\n",
            "  8.64257812e-02  1.84631348e-03 -2.69775391e-02  1.77734375e-01\n",
            " -1.09375000e-01 -7.56835938e-02 -2.40478516e-02  2.05078125e-01\n",
            " -5.90820312e-02 -1.13281250e-01  5.39062500e-01  2.50000000e-01\n",
            " -2.79296875e-01  1.39648438e-01 -7.71484375e-02  5.71289062e-02\n",
            " -1.24511719e-01  3.10546875e-01 -2.22656250e-01  3.55468750e-01\n",
            "  2.39257812e-01 -2.89306641e-02 -1.59179688e-01 -1.57226562e-01\n",
            " -2.95410156e-02  3.75976562e-02  1.66015625e-01  5.39550781e-02\n",
            " -2.17773438e-01 -4.33593750e-01  3.10546875e-01  2.09960938e-01\n",
            " -6.34765625e-02  6.39648438e-02 -2.22656250e-01  1.26953125e-01\n",
            " -1.11328125e-01 -8.83789062e-02 -7.27539062e-02  8.72802734e-03\n",
            "  2.75390625e-01 -8.59375000e-02 -2.42187500e-01  1.64062500e-01\n",
            "  1.01562500e-01  2.73437500e-01  8.78906250e-02 -2.38281250e-01\n",
            " -4.76562500e-01 -1.45507812e-01  2.48046875e-01 -1.45507812e-01\n",
            "  2.94921875e-01 -4.39453125e-01  3.80859375e-02  7.38525391e-03\n",
            " -2.96875000e-01 -2.87109375e-01  4.62890625e-01  1.65039062e-01\n",
            "  2.96875000e-01 -1.93359375e-01  2.07031250e-01 -4.66796875e-01\n",
            "  7.37304688e-02 -2.17773438e-01 -2.13867188e-01 -5.39062500e-01\n",
            " -1.10351562e-01  3.82812500e-01 -7.22656250e-02  1.68945312e-01\n",
            " -4.71191406e-02 -3.75976562e-02 -2.75390625e-01 -8.10546875e-02\n",
            " -1.08398438e-01 -5.23437500e-01  6.98242188e-02 -4.37011719e-02\n",
            " -9.42382812e-02  3.86718750e-01 -6.13281250e-01 -1.83105469e-02\n",
            " -3.85742188e-02 -1.69921875e-01  1.00585938e-01 -5.19531250e-01\n",
            "  4.33593750e-01 -7.81250000e-01  3.02734375e-01 -5.27343750e-01\n",
            "  1.90429688e-01  4.15039062e-02 -1.68945312e-01 -1.33789062e-01\n",
            "  1.23535156e-01  2.94921875e-01  1.61132812e-01  2.51953125e-01\n",
            "  1.38671875e-01 -7.22656250e-02 -5.54199219e-02  2.43164062e-01\n",
            " -3.49609375e-01 -1.09375000e-01  3.02734375e-01  1.27929688e-01\n",
            "  8.59375000e-02 -2.36328125e-01  1.10839844e-01 -1.38671875e-01\n",
            " -2.63671875e-01 -5.95703125e-02 -3.14941406e-02 -4.08203125e-01\n",
            " -6.59179688e-02  5.73730469e-02 -2.11914062e-01 -3.26171875e-01\n",
            " -7.95898438e-02  1.78710938e-01 -2.47070312e-01  2.09960938e-01\n",
            " -4.29687500e-01 -7.03125000e-02 -3.30078125e-01 -5.76782227e-03\n",
            "  1.72851562e-01  1.63085938e-01 -1.07910156e-01  9.42382812e-02\n",
            " -1.99218750e-01 -2.11914062e-01  7.37304688e-02  1.82617188e-01\n",
            " -1.47460938e-01  9.17968750e-02 -1.06201172e-02 -1.27929688e-01\n",
            "  6.10351562e-04 -4.49218750e-02 -1.28906250e-01 -2.63671875e-01\n",
            "  1.88476562e-01 -2.14843750e-01 -1.55273438e-01  1.73828125e-01\n",
            "  6.56127930e-03  1.09252930e-02 -6.44531250e-02  2.94921875e-01\n",
            "  3.12500000e-01  1.20605469e-01  3.97949219e-02  8.05664062e-02\n",
            "  9.47265625e-02  1.11328125e-01 -2.98828125e-01  1.09375000e-01\n",
            " -2.05078125e-01 -1.20605469e-01  2.98828125e-01 -7.22656250e-02\n",
            "  3.14453125e-01  1.29882812e-01  3.49121094e-02 -9.71679688e-02\n",
            " -2.25585938e-01 -7.04956055e-03  3.06640625e-01 -1.77734375e-01\n",
            "  1.04492188e-01  7.42187500e-02  3.00781250e-01 -4.33593750e-01\n",
            "  9.13085938e-02  4.12597656e-02 -1.15722656e-01  1.77001953e-02\n",
            "  1.90429688e-01 -1.07421875e-01 -1.20117188e-01 -1.71875000e-01\n",
            " -7.81250000e-02  2.62451172e-02  3.80859375e-02 -2.19726562e-01\n",
            " -1.10351562e-01 -6.05468750e-02 -4.41406250e-01  2.19726562e-01\n",
            "  3.34472656e-02  5.68847656e-02 -3.34472656e-02  2.53906250e-01\n",
            " -9.37500000e-02 -4.78515625e-02  1.36718750e-01  1.10839844e-01\n",
            " -1.21582031e-01  1.37695312e-01 -3.32031250e-02  3.08593750e-01\n",
            "  3.41796875e-02 -1.83105469e-02 -7.56835938e-02  6.59179688e-02\n",
            " -1.50390625e-01 -9.52148438e-02 -1.16210938e-01 -1.12304688e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors['india'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6XEjbWl_6Zx",
        "outputId": "7f77a79a-2227-41dd-9153-84414d9ef11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any available word here is 300 dimensional vector."
      ],
      "metadata": {
        "id": "CB5GiqGMAKVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Similar words\n",
        "\n",
        "- well trained vectors can capture similarity"
      ],
      "metadata": {
        "id": "z7BtstEQAROm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check below words present in model\n",
        "\n",
        "print('king' in word_vectors)\n",
        "print('woman' in word_vectors)\n",
        "print('man' in word_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBq490h6AEmE",
        "outputId": "5afb506b-b892-4edb-faa3-2616feda4710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## king + woman - man = ?"
      ],
      "metadata": {
        "id": "YVM7xUSdAr1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors.most_similar(positive=['king', 'woman'], negative=['man']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHTgSKv_AgXH",
        "outputId": "65bedf91-d225-4d1c-928f-a4a401a4f82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.5181134343147278), ('sultan', 0.5098593831062317), ('monarchy', 0.5087411999702454)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "see, output captures similarity"
      ],
      "metadata": {
        "id": "sFJaUBUyBB71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('independence' in word_vectors)\n",
        "print('uk' in word_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDN5HmQkA7GM",
        "outputId": "98254294-0dc1-4437-e7fd-b46d8853ef67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors.most_similar(positive=['India', 'war']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFNnRTrbBRC2",
        "outputId": "a7ad8d81-d9e4-4508-d37a-3d9b21618fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('wars', 0.6058735251426697), ('subcontinent', 0.5804473161697388), ('Alwine_Goveas_Kulshekar_Mangalore', 0.5778571367263794), ('sub_continent', 0.5734809041023254), ('Maurice_Quadras_Mangalore', 0.5726993083953857), ('Sri_Lanka', 0.5608813762664795), ('Indias', 0.560208261013031), ('Pakistan', 0.5474928617477417), ('Operation_Parakaram', 0.5458939671516418), ('subcontinent_partition', 0.5419802069664001)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check similarity b/w word pairs"
      ],
      "metadata": {
        "id": "R9SX487JCY_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_vectors.similarity('man', 'woman'))\n",
        "print(word_vectors.similarity('India', 'Pakistan'))\n",
        "print(word_vectors.similarity('India', 'Brazil'))\n",
        "print(word_vectors.similarity('paper', 'man'))\n",
        "print(word_vectors.similarity('Mars', 'computer'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqO4WWHYBia4",
        "outputId": "f6e1a47d-0c0a-4bfa-b99b-7e2d3535a742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.76640123\n",
            "0.6706861\n",
            "0.49957347\n",
            "0.085691616\n",
            "0.0976148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results shows us that if vector embedding done nicely we can capture similarity between words and it helps in training significantly."
      ],
      "metadata": {
        "id": "TrpSMgAODRgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How are token embeddings created for LLMs?\n",
        "\n",
        "- start with vocab\n",
        "- tokens for that vocab\n",
        "- we have token ids for those tokens\n",
        "- every token ids converted to embedding vectors\n",
        "- for GPT-2 vocab size was 50257 and dimension was 768 for small model.\n",
        "- so total weights will be 50257 * 768 and this is called embedding layer weight matrix.\n",
        "\n",
        "\n",
        "## How actually training works?\n",
        "- we fixed the dimension and vocab size.\n",
        "- initialized embedding weights with random values.\n",
        "- serves as starting point for LLM learning process.\n",
        "- weights are optimized as part of LLM training process.\n",
        "- we have the training data for example google news data, this kind of training data is used to get ideal weight similar to neural networks training via backpropogation.\n"
      ],
      "metadata": {
        "id": "aWHLEBTyDhhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example"
      ],
      "metadata": {
        "id": "5i-_JUTOHfHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "input_ids = torch.tensor([2, 3, 5, 1])"
      ],
      "metadata": {
        "id": "pvbx0s5DHd6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 6\n",
        "output_dim = 3\n",
        "\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaysg15mNVTT",
        "outputId": "405e017a-8a9f-4272-bb57-1db2ff8a697f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9920b1bb10>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "2TRxy-OyN3HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(embedding_layer))"
      ],
      "metadata": {
        "id": "xXKcTfx1ODeC",
        "outputId": "fdfae3f8-0353-4a3a-c837-7c382334eba7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.modules.sparse.Embedding'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer)"
      ],
      "metadata": {
        "id": "srcEDE87OGTa",
        "outputId": "6e0b3c6a-7df9-4e4b-df3e-5c6a8680926e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(6, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.weight) # initial weights"
      ],
      "metadata": {
        "id": "yozXcHnlOHx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48bb818-a7ec-4bb8-cab4-70acf998e0a0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3374, -0.1778, -0.1690],\n",
            "        [ 0.9178,  1.5810,  1.3010],\n",
            "        [ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-1.1589,  0.3255, -0.6315],\n",
            "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the weights which we will optimize in LLM training. (will see in future notes)\n",
        "\n",
        "1. embedding layer weights\n",
        "2. actual weights needed to predict next word."
      ],
      "metadata": {
        "id": "qEuT7VSUOrnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(torch.tensor([3])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpdL88FEOjvF",
        "outputId": "20fda049-8ee4-4c66-be0d-2438cd842566"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvswsmeuSLrx",
        "outputId": "51d834b0-19ea-4ee1-bac5-df52a82764fe"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2753, -0.2010, -0.1606],\n",
            "        [-0.4015,  0.9666, -1.1481],\n",
            "        [-2.8400, -0.7849, -1.4096],\n",
            "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is same as neural network linear layer. Both embedding layer and NN linear layer lead to same output.\n",
        "\n",
        "Embedding layer is much more computationally efficient, since NN linear layer has many unnecessary multiplications with zero."
      ],
      "metadata": {
        "id": "9iUgrxc4U7MQ"
      }
    }
  ]
}