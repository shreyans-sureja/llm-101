{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BYTE PAIR ENCODING",
   "id": "39d06a9d732af7f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### also use in morden LLM like OpenAI's GPT",
   "id": "e5c46747233021e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Types of tokenizer - \n",
    "\n",
    "- word based tokenizer\n",
    "    - ['Hi', 'how', 'are', 'yoy', '?'] \n",
    "    - out of vocab is huge problem\n",
    "    - boy and boys treated different and similarity not captured.\n",
    "- character based tokenizer\n",
    "    - ['H', 'i', ...] \n",
    "    - small vocab \n",
    "    - solve out of vocab problem\n",
    "    - meaning associated with words is lost\n",
    "    - tokenized sequence become much longer than raw text.\n",
    "    - ['h','o', 'w'] 3 tokens in char based but 1 token in word \n",
    "- sub-word based tokenizer\n",
    "    - best of both worlds\n",
    "    - do not split frequently used words into smaller sub words.\n",
    "    - split the rare words into smaller meaningful sub words.\n",
    "    - 'boys' -> ['boy', 's'] \n",
    "    - helps thr model understand similarity b/w words like - token, tokens, tokenizer, tokenization"
   ],
   "id": "1ae04d80d10e4609"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "BPE is a sub word tokenization algorithm\n",
    "\n",
    "most common pair of consecutive bytes of data is replaced with a byte that does not occur in data"
   ],
   "id": "c3ec748a3d6c2df2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "data = aaabdaaabac\n",
    "\n",
    "byte pair 'aa' occurs the most. We will replace it with Z as Z does not occur in the data.\n",
    "\n",
    "compressed data - ZabdZabac\n",
    "\n",
    "repeat\n",
    "- most freq pair now = ab\n",
    "\n",
    "compressed data = ZYdZYac\n",
    "\n",
    "no byte pair occurs more than once.  -> stop\n",
    "\n",
    "stopping criteria can either be the token count or num of iterations."
   ],
   "id": "9ec96c90493266fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# algorithm",
   "id": "9313070408dadf22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T13:49:07.544728Z",
     "start_time": "2025-10-04T13:49:05.651626Z"
    }
   },
   "cell_type": "code",
   "source": "! pip3 install tiktoken",
   "id": "1d7d599b09568c09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\r\n",
      "  Downloading tiktoken-0.11.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\r\n",
      "  Downloading regex-2025.9.18-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/miniconda3/envs/ml-dev/lib/python3.13/site-packages (from tiktoken) (2.32.5)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/ml-dev/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/ml-dev/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/ml-dev/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/ml-dev/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\r\n",
      "Downloading tiktoken-0.11.0-cp313-cp313-macosx_11_0_arm64.whl (997 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m997.1/997.1 kB\u001B[0m \u001B[31m11.4 MB/s\u001B[0m  \u001B[33m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading regex-2025.9.18-cp313-cp313-macosx_11_0_arm64.whl (287 kB)\r\n",
      "Installing collected packages: regex, tiktoken\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2/2\u001B[0m [tiktoken]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed regex-2025.9.18 tiktoken-0.11.0\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T13:49:28.242866Z",
     "start_time": "2025-10-04T13:49:28.218464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ],
   "id": "237e6246aac22f7c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.11.0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T13:49:47.890488Z",
     "start_time": "2025-10-04T13:49:41.668911Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = tiktoken.get_encoding(\"gpt2\")",
   "id": "f34e8be625d04538",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T13:50:23.845403Z",
     "start_time": "2025-10-04T13:50:23.838823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ],
   "id": "b26d25bedd597774",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T13:50:28.089195Z",
     "start_time": "2025-10-04T13:50:28.086937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ],
   "id": "6c4e8b574e944639",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
