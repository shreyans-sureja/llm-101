{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPnP3oKYyWR+B6oJkuQ3GJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyans-sureja/llm-101/blob/main/34_evaluating_finetuned_LLM_using_Ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating fine-tuned LLM using Ollama"
      ],
      "metadata": {
        "id": "WxeUa35qZErN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code from previous note"
      ],
      "metadata": {
        "id": "TfwakuBphltJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a16d5RywY9Kg",
        "outputId": "780fd61f-00cc-4c35-a04c-ea0a08ef6813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n",
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "import ssl\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "    ssl_context = ssl.create_default_context()\n",
        "    ssl_context.check_hostname = False\n",
        "    ssl_context.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))\n",
        "\n",
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "\n",
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = self._format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def _format_input(self, entry):\n",
        "      instruction_text = (\n",
        "          f\"Below is an instruction that describes a task. \"\n",
        "          f\"Write a response that appropriately completes the request.\"\n",
        "          f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "      )\n",
        "\n",
        "      input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "      return instruction_text + input_text\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "from functools import partial\n",
        "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "03skBKKiWlKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ec9279-e82a-45f3-899f-15518d529cf7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed_all(123)\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    class LayerNorm(nn.Module):\n",
        "      def __init__(self, emb_dim):\n",
        "          super().__init__()\n",
        "          self.eps = 1e-5\n",
        "          self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "          self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "      def forward(self, x):\n",
        "          mean = x.mean(dim=-1, keepdim=True)\n",
        "          var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "          norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "          return self.scale * norm_x + self.shift\n",
        "\n",
        "    class GELU(nn.Module):\n",
        "      def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "      def forward(self, x):\n",
        "        # approx GeLu function\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "    class FeedForward(nn.Module):\n",
        "      def __init__(self, cfg):\n",
        "          super().__init__()\n",
        "          self.layers = nn.Sequential(\n",
        "              nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "              GPTModel.GELU(),\n",
        "              nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "          )\n",
        "\n",
        "      def forward(self, x):\n",
        "          return self.layers(x)\n",
        "\n",
        "    class MultiHeadAttention(nn.Module):\n",
        "      def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "          super().__init__()\n",
        "          assert (d_out % num_heads == 0), \\\n",
        "              \"d_out must be divisible by num_heads\"\n",
        "\n",
        "          self.d_out = d_out\n",
        "          self.num_heads = num_heads\n",
        "          self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "          self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "          self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "          self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "          self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "          self.dropout = nn.Dropout(dropout)\n",
        "          self.register_buffer(\n",
        "              \"mask\",\n",
        "              torch.triu(torch.ones(context_length, context_length),\n",
        "                        diagonal=1)\n",
        "          )\n",
        "\n",
        "      def forward(self, x):\n",
        "          b, num_tokens, d_in = x.shape\n",
        "\n",
        "          keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "          queries = self.W_query(x)\n",
        "          values = self.W_value(x)\n",
        "\n",
        "          # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "          # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "          keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "          values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "          queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "          # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "          keys = keys.transpose(1, 2)\n",
        "          queries = queries.transpose(1, 2)\n",
        "          values = values.transpose(1, 2)\n",
        "\n",
        "          # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "          attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "          # Original mask truncated to the number of tokens and converted to boolean\n",
        "          mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "          # Use the mask to fill attention scores\n",
        "          attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "          attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "          attn_weights = self.dropout(  attn_weights)\n",
        "\n",
        "          # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "          context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "          # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "          context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "          context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "          return context_vec\n",
        "\n",
        "    class TransformerBlock(nn.Module):\n",
        "        def __init__(self, cfg):\n",
        "            super().__init__()\n",
        "            self.att = GPTModel.MultiHeadAttention(\n",
        "                d_in=cfg[\"emb_dim\"],\n",
        "                d_out=cfg[\"emb_dim\"],\n",
        "                context_length=cfg[\"context_length\"],\n",
        "                num_heads=cfg[\"n_heads\"],\n",
        "                dropout=cfg[\"drop_rate\"],\n",
        "                qkv_bias=cfg[\"qkv_bias\"])\n",
        "            self.ff = GPTModel.FeedForward(cfg)\n",
        "            self.norm1 = GPTModel.LayerNorm(cfg[\"emb_dim\"])\n",
        "            self.norm2 = GPTModel.LayerNorm(cfg[\"emb_dim\"])\n",
        "            self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        def forward(self, x):\n",
        "            # Shortcut connection for attention block\n",
        "            shortcut = x\n",
        "            x = self.norm1(x)\n",
        "            x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "            x = self.drop_shortcut(x)\n",
        "            x = x + shortcut  # Add the original input back\n",
        "\n",
        "            # Shortcut connection for feed forward block\n",
        "            shortcut = x\n",
        "            x = self.norm2(x)\n",
        "            x = self.ff(x)\n",
        "            x = self.drop_shortcut(x)\n",
        "            x = x + shortcut  # Add the original input back\n",
        "\n",
        "            return x\n",
        "\n",
        "    # GPTModel itself\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # Use a placeholder for TransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[GPTModel.TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        # Use a placeholder for LayerNorm\n",
        "        self.final_norm = GPTModel.LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "\n",
        "        # dropout helps in generalization and avoid overfitting\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n"
      ],
      "metadata": {
        "id": "qnk-HptmYRF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenUtils:\n",
        "  @staticmethod\n",
        "  def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "  @staticmethod\n",
        "  def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n"
      ],
      "metadata": {
        "id": "yXyUpMKDYudX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class GPT2Weightloader:\n",
        "\n",
        "  @staticmethod\n",
        "  def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        GPT2Weightloader.download_file(file_url, file_path, backup_url)\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
        "    params = GPT2Weightloader.load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "  @staticmethod\n",
        "  def download_file(url, destination, backup_url=None):\n",
        "    def _attempt_download(download_url):\n",
        "        response = requests.get(download_url, stream=True, timeout=60)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "\n",
        "        # Check if file exists and has same size\n",
        "        if os.path.exists(destination):\n",
        "            file_size_local = os.path.getsize(destination)\n",
        "            if file_size and file_size == file_size_local:\n",
        "                print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                return True\n",
        "\n",
        "        block_size = 1024  # 1 KB\n",
        "        desc = os.path.basename(download_url)\n",
        "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=desc) as progress_bar:\n",
        "            with open(destination, \"wb\") as file:\n",
        "                for chunk in response.iter_content(chunk_size=block_size):\n",
        "                    if chunk:\n",
        "                        file.write(chunk)\n",
        "                        progress_bar.update(len(chunk))\n",
        "        return True\n",
        "\n",
        "    try:\n",
        "        if _attempt_download(url):\n",
        "            return\n",
        "    except requests.exceptions.RequestException:\n",
        "        if backup_url is not None:\n",
        "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
        "            try:\n",
        "                if _attempt_download(backup_url):\n",
        "                    return\n",
        "            except requests.exceptions.RequestException:\n",
        "                pass\n",
        "\n",
        "        error_message = (\n",
        "            f\"Failed to download from both primary URL ({url})\"\n",
        "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
        "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
        "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
        "        )\n",
        "        print(error_message)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "  # Alternative way using `requests`\n",
        "  \"\"\"\n",
        "  def download_file(url, destination):\n",
        "      # Send a GET request to download the file in streaming mode\n",
        "      response = requests.get(url, stream=True)\n",
        "\n",
        "      # Get the total file size from headers, defaulting to 0 if not present\n",
        "      file_size = int(response.headers.get(\"content-length\", 0))\n",
        "\n",
        "      # Check if file exists and has the same size\n",
        "      if os.path.exists(destination):\n",
        "          file_size_local = os.path.getsize(destination)\n",
        "          if file_size == file_size_local:\n",
        "              print(f\"File already exists and is up-to-date: {destination}\")\n",
        "              return\n",
        "\n",
        "      # Define the block size for reading the file\n",
        "      block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "      # Initialize the progress bar with total file size\n",
        "      progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
        "      with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "          # Open the destination file in binary write mode\n",
        "          with open(destination, \"wb\") as file:\n",
        "              # Iterate over the file data in chunks\n",
        "              for chunk in response.iter_content(block_size):\n",
        "                  progress_bar.update(len(chunk))  # Update progress bar\n",
        "                  file.write(chunk)  # Write the chunk to the file\n",
        "  \"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params\n",
        "\n",
        "  @staticmethod\n",
        "  def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n",
        "\n",
        "  @staticmethod\n",
        "  def load_weights_into_gpt(gpt, params):\n",
        "      gpt.pos_emb.weight = GPT2Weightloader.assign(gpt.pos_emb.weight, params['wpe'])\n",
        "      gpt.tok_emb.weight = GPT2Weightloader.assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "      for b in range(len(params[\"blocks\"])):\n",
        "          q_w, k_w, v_w = np.split(\n",
        "              (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "          gpt.trf_blocks[b].att.W_query.weight = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "          gpt.trf_blocks[b].att.W_key.weight = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "          gpt.trf_blocks[b].att.W_value.weight = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "          q_b, k_b, v_b = np.split(\n",
        "              (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "          gpt.trf_blocks[b].att.W_query.bias = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "          gpt.trf_blocks[b].att.W_key.bias = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "          gpt.trf_blocks[b].att.W_value.bias = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "          gpt.trf_blocks[b].att.out_proj.weight = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].att.out_proj.weight,\n",
        "              params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "          gpt.trf_blocks[b].att.out_proj.bias = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].att.out_proj.bias,\n",
        "              params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "          gpt.trf_blocks[b].ff.layers[0].weight = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "              params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "          gpt.trf_blocks[b].ff.layers[0].bias = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "              params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "          gpt.trf_blocks[b].ff.layers[2].weight = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "              params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "          gpt.trf_blocks[b].ff.layers[2].bias = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "              params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "          gpt.trf_blocks[b].norm1.scale = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].norm1.scale,\n",
        "              params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "          gpt.trf_blocks[b].norm1.shift = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].norm1.shift,\n",
        "              params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "          gpt.trf_blocks[b].norm2.scale = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].norm2.scale,\n",
        "              params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "          gpt.trf_blocks[b].norm2.shift = GPT2Weightloader.assign(\n",
        "              gpt.trf_blocks[b].norm2.shift,\n",
        "              params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "      gpt.final_norm.scale = GPT2Weightloader.assign(gpt.final_norm.scale, params[\"g\"])\n",
        "      gpt.final_norm.shift = GPT2Weightloader.assign(gpt.final_norm.shift, params[\"b\"])\n",
        "      gpt.out_head.weight = GPT2Weightloader.assign(gpt.out_head.weight, params[\"wte\"])\n"
      ],
      "metadata": {
        "id": "TyejSWTPYKRv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = GPT2Weightloader.download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "GPT2Weightloader.load_weights_into_gpt(model, params)\n",
        "model.to(device) # Add this line to move the model to the correct device\n",
        "model.eval();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0uJSPu5ZBwP",
        "outputId": "a1c39c22-23c4-4e99-c2a2-2d0733dff4ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_input(entry):\n",
        "      instruction_text = (\n",
        "          f\"Below is an instruction that describes a task. \"\n",
        "          f\"Write a response that appropriately completes the request.\"\n",
        "          f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "      )\n",
        "\n",
        "      input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "      return instruction_text + input_text\n"
      ],
      "metadata": {
        "id": "SIoM9OcGZmyo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = TokenUtils.text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = TokenUtils.token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n",
        "\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ],
      "metadata": {
        "id": "kzpbeB2Sbt8u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "id": "wnTTLgWve_Rc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc56c793-7cb9-44f6-d6f0-ec5ccb9f1a40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
            "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
            "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.533, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.568, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.604, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
            "Ep 1 (Step 000090): Train loss 0.563, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.504, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.565, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
            "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.663\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Training completed in 1.58 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "N3NpeEiqfVlw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "qejc18ktgUcB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "19e65538-d807-4319-ae9c-eca441f0d1f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to measure performance?"
      ],
      "metadata": {
        "id": "mFhZyMcxosX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On previous note -  \\\n",
        "Desired respoonse: \"The meal is cooked by the chef every day\"\n",
        "LLM response: \"The meal is prepared by the chef every day\".\n",
        "\n",
        "How to quantify the performance of LLM."
      ],
      "metadata": {
        "id": "-Olf8-3oowQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stage 3:**\n",
        "1. Extracting responses\n",
        "2. Qualitative evaluation\n",
        "3. Scoring the responses"
      ],
      "metadata": {
        "id": "9_eyoPHeprPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate results for 3 test set samples"
      ],
      "metadata": {
        "id": "Zouq5iC5rOYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "torch.cuda.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx= TokenUtils.text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = TokenUtils.token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ],
      "metadata": {
        "id": "P0i2G7WpprEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a730fdc5-8bf8-4ea0-8874-9e811f35787f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> A thunderstorm is a type of cloud that typically forms in the atmosphere over a region of high pressure. It typically produces a strong wind that blows across the area, creating a dense, dense cloud.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is George Bernard Shaw.\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see based on the test set instructions, given responses, and the model's responses, the model performs relatively well.\n",
        "\n",
        "The answers to the first instruction is clearly correct, while the second answer and the third answers are not correct.\n",
        "\n",
        "This is because we have done the fine-tuning for only 1 epoch due to hardware limitations. To get better results, we need to increase the epochs to at least 2."
      ],
      "metadata": {
        "id": "Xbgnlvu1u9Pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most importantly, we can see that model evaluation is not as straightforward as in the previous notes, where we simply calculated the percentage of correct spam/non-spam class labels to obtain the classification accuracy.\n",
        "\n",
        "In practice, instruction-finetuned LLMs\n",
        "such as chatbots are evaluated via multiple approaches:\n",
        "\n",
        "1. Short-answer and multiple choice benchmarks such as MMLU (\"Measuring Massive Multitask Language Understanding,\" https://arxiv.org/abs/2009.\n",
        "03300), which test the general knowledge of a model.\n",
        "\n",
        "2. Human preference comparison to other LLMs, such as LMSYS chatbot\n",
        "arena (https://arena.lmsys.org).\n",
        "\n",
        "3. Automated conversational benchmarks, where another LLM like GPT-4 is used to evaluate the responses, such as AlpacaEval (https://tatsulab.github.io/alpaca_eval/).\n",
        "completes the request."
      ],
      "metadata": {
        "id": "_Ayg0AcQvPGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will implement an approach similar to method 3, which involves evaluating the responses automatically using another LLM.\n",
        "\n",
        "This will allow us to efficiently assess the quality of the generated responses without the need for extensive human involvement, thereby saving time and resources while still obtaining\n",
        "meaningful performance indicators."
      ],
      "metadata": {
        "id": "35Qw0e86wxwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate result for entire test set"
      ],
      "metadata": {
        "id": "WzUPt5bH58X3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=TokenUtils.text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = TokenUtils.token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
      ],
      "metadata": {
        "id": "m7OLYnFqpqmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47d537d-3c13-47d6-d726-35f121573df3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 110/110 [01:29<00:00,  1.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verifying the test data result.\n",
        "print(test_data[0])"
      ],
      "metadata": {
        "id": "EgpO8z9zovyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3209b92d-6105-4cd3-c3de-1948c6566100"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model for future usecase."
      ],
      "metadata": {
        "id": "6bryO6rW6gHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")\n",
        "\n",
        "# Load model via\n",
        "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d_fvrSo6g5I",
        "outputId": "55f4fbd7-bd01-4b1e-9745-cb2f94ffc100"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the finetuned LLM"
      ],
      "metadata": {
        "id": "bVU_9dGV7tYD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implement a method to automate the response evaluation of the finetuned LLM using another, larger LLM.\n",
        "\n",
        "To implement the evaluation step which involves evaluating test set responses in an automated fashion, we utilize an existing instruction-finetuned 8 billion parameter Llama\n",
        "3 model developed by Meta AI.\n",
        "\n",
        "This model can be run locally using the open-source Ollama\n",
        "application (https://ollama.com)."
      ],
      "metadata": {
        "id": "YJEf0R-T76lW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ollama is an efficient application for running LLMs on a laptop.\n",
        "\n",
        "It serves as a wrapper around the open-source llama.cpp library (https://github.com/ggerganov/llama.cpp), which\n",
        "implements LLMs in pure C/C++ to maximize efficiency.\n",
        "\n",
        "However, note that Ollama is only a tool for generating text using LLMs (inference) and does not support training or finetuning\n",
        "LLMs.\n",
        "\n",
        "The following code verifies that the Ollama session is running properly before we use Ollama to evaluate the test set responses generated previously:"
      ],
      "metadata": {
        "id": "uuIOlBlA8NFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
        "print(\"Ollama running:\", check_if_running(\"ollama\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "vCxHBb_y7wz5",
        "outputId": "aee445e4-b828-42a6-c217-76a1b52470d1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Ollama not running. Launch ollama before proceeding.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-242962959.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mollama_running\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ollama not running. Launch ollama before proceeding.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ollama running:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_if_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ollama\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Ollama not running. Launch ollama before proceeding."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An alternative to the ollama run command for interacting with the model is through its REST API using Python.\n",
        "\n",
        "Use ngrok to connect via api."
      ],
      "metadata": {
        "id": "zYUsgJeQ8h1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "def query_model(\n",
        "    prompt,\n",
        "    model=\"llama3\",\n",
        "    url= \"<Ngrok url>\" + \"/api/chat\"\n",
        "):\n",
        "    # Create the data payload as a dictionary\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {     # Settings below are required for deterministic responses\n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "    # Create a request object, setting the method to POST and adding necessary headers\n",
        "    request = urllib.request.Request(\n",
        "        url,\n",
        "        data=payload,\n",
        "        method=\"POST\"\n",
        "    )\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "\n",
        "    # Send the request and capture the response\n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        # Read and decode the response\n",
        "        while True:\n",
        "            line = response.readline().decode(\"utf-8\")\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data"
      ],
      "metadata": {
        "id": "B2EImqn4_H2l"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"llama3\"\n",
        "result = query_model(\"What do Llamas eat?\", model)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf7iAef2ir85",
        "outputId": "67931eda-6b14-40ea-f74e-3a9d6883769c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
            "\n",
            "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
            "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
            "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
            "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
            "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
            "\n",
            "In the wild, llamas might also eat:\n",
            "\n",
            "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
            "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
            "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
            "\n",
            "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the query_model function defined earlier, we can evaluate the responses generated by our finetuned model with a prompt that prompts the Llama 3 model to rate our finetuned model's responses on a scale from 0 to 100 based on the given test set response\n",
        "as reference."
      ],
      "metadata": {
        "id": "Tue8RAX8lrnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for entry in test_data[:3]:\n",
        "    prompt = (\n",
        "        f\"Given the input `{format_input(entry)}` \"\n",
        "        f\"and correct output `{entry['output']}`, \"\n",
        "        f\"score the model response `{entry['model_response']}`\"\n",
        "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "    )\n",
        "    print(\"\\nDataset response:\")\n",
        "    print(\">>\", entry['output'])\n",
        "    print(\"\\nModel response:\")\n",
        "    print(\">>\", entry[\"model_response\"])\n",
        "    print(\"\\nScore:\")\n",
        "    print(\">>\", query_model(prompt))\n",
        "    print(\"\\n-------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5BhjIREiyaW",
        "outputId": "b5e9f907-690f-4145-a0fa-3d5c2916a7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "Score:\n",
            ">> I'd rate the model response \"The car is as fast as a bullet.\" an 85 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The response uses a simile correctly, comparing the speed of the car to something else (in this case, a bullet).\n",
            "* The comparison is relevant and makes sense, as bullets are known for their high velocity.\n",
            "* The phrase \"as fast as\" is used correctly to introduce the simile.\n",
            "\n",
            "The only reason I wouldn't give it a perfect score is that some people might find the comparison slightly less vivid or evocative than others. For example, comparing something to lightning (as in the original response) can be more dramatic and attention-grabbing. However, \"as fast as a bullet\" is still a strong and effective simile that effectively conveys the idea of the car's speed.\n",
            "\n",
            "Overall, I think the model did a great job!\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> A thunderstorm is a type of cloud that typically forms in the atmosphere over a region of high pressure. It typically produces a strong wind that blows across the area, creating a dense, dense cloud.\n",
            "\n",
            "Score:\n",
            ">> I'd score this model response as 20 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The response doesn't directly answer the question about what type of cloud is typically associated with thunderstorms.\n",
            "* Instead, it provides a general description of thunderstorms, which is not relevant to the original question.\n",
            "* The response also contains some inaccuracies, such as stating that thunderstorms form over high pressure regions (thunderstorms can occur in various weather patterns).\n",
            "\n",
            "A good model response should directly answer the question, provide accurate and relevant information, and avoid unnecessary details. In this case, the response fails to meet these criteria, which is why I'd score it relatively low.\n",
            "\n",
            "-------------------------\n",
            "\n",
            "Dataset response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is George Bernard Shaw.\n",
            "\n",
            "Score:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llama 3 model provides reasonable evaluations and is capable of assigning partial points when a model's answer is not entirely correct.\n",
        "\n",
        "The previous prompt returns highly detailed evaluations in addition to the score.\n",
        "\n",
        "We can modify the prompt to just generate integer scores ranging from 0 to 100, where 100 represents the best possible score.\n",
        "\n",
        "This modification allows us to calculate an average score\n",
        "for our model, which serves as a more concise and quantitative assessment of its performance."
      ],
      "metadata": {
        "id": "HMFKcje9l1H8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for entry in test_data[:2]:\n",
        "    prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry['model_response']}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "    score = query_model(prompt, model)\n",
        "    print(\"\\nDataset response:\")\n",
        "    print(\">>\", entry['output'])\n",
        "    print(\"\\nModel response:\")\n",
        "    print(\">>\", entry[\"model_response\"])\n",
        "    print(\"\\nScore:\")\n",
        "    print(\">>\", query_model(prompt, model))\n",
        "    print(\"\\n-------------------------\")"
      ],
      "metadata": {
        "id": "uIdBMV3njZyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dataset response:\n",
        "The car is as fast as lightning.\n",
        "\n",
        "Model response:\n",
        "The car is as fast as a bullet.\n",
        "\n",
        "Score: 85\n"
      ],
      "metadata": {
        "id": "T_K07X86mFXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use below function to generate score of our output using json data."
      ],
      "metadata": {
        "id": "kF5_Pd4PmSRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
        "        prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry[json_key]}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "        score = query_model(prompt, model)\n",
        "        try:\n",
        "            scores.append(int(score))\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert score: {score}\")\n",
        "            continue\n",
        "\n",
        "    return scores"
      ],
      "metadata": {
        "id": "vbWlMH2cjzXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you run the above code, the evaluation output shows that our finetuned model achieves an average score above 50,\n",
        "which provides a useful benchmark for comparison against other models or for experimenting with different training configurations to improve the model's performance.\n",
        "\n",
        "It's worth noting that Ollama is not entirely deterministic at the time of this writing, which means that the scores you obtain might slightly vary from the ones presented above.\n",
        "    \n",
        "To obtain more robust results, you can repeat the evaluation multiple times and average the resulting scores."
      ],
      "metadata": {
        "id": "dswftnvsmdMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To further improve our model's performance, we can explore various strategies, such as:\n",
        "\n",
        "(1) Adjusting the hyperparameters during finetuning, such as the learning rate, batch size, or number of epochs.\n",
        "\n",
        "\n",
        "(2) Increasing the size of the training dataset or diversifying the examples to cover a broader range of topics and styles.\n",
        "\n",
        "\n",
        "(3) Experimenting with different prompts or instruction formats to guide the model's responses more effectively.\n",
        "\n",
        "\n",
        "(4) Considering the use of a larger pretrained model, which may have greater capacity to capture complex patterns and generate more accurate responses.\n",
        "\n",
        "(5) We can also use parameter efficient fine-tuning techniques like LoRA."
      ],
      "metadata": {
        "id": "5sWBJEsRmtyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KrZ9K2NLm5LF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}